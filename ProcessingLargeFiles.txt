If I knew the program would be used to process 10GB CSV files, I would rework the CSV reading logic to use streaming (row-by-row reading) instead of loading all rows into memory. I would buffer rows in batches of 5,000â€“10,000 records, transform and validate them in chunks, and then send them to the database using SqlBulkCopy. 